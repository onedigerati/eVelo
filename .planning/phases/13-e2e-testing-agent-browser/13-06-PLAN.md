---
phase: 13-e2e-testing-agent-browser
plan: 06
type: execute
wave: 3
depends_on: ["13-02", "13-03", "13-04"]
files_modified:
  - .github/workflows/e2e.yml
  - test/e2e/run-all.js
autonomous: true

must_haves:
  truths:
    - "GitHub Actions workflow runs E2E tests on PR"
    - "Test runner executes smoke, workflow, responsive tests in sequence"
    - "CI fails if any E2E test fails"
    - "Workflow uses agent-browser with Chromium"
  artifacts:
    - path: ".github/workflows/e2e.yml"
      provides: "GitHub Actions E2E test workflow"
      min_lines: 30
    - path: "test/e2e/run-all.js"
      provides: "Test orchestrator that runs all E2E tests"
      min_lines: 40
  key_links:
    - from: ".github/workflows/e2e.yml"
      to: "test/e2e/run-all.js"
      via: "npm run test:e2e"
      pattern: "npm run test:e2e"
    - from: ".github/workflows/e2e.yml"
      to: "agent-browser"
      via: "agent-browser install"
      pattern: "agent-browser install"
---

<objective>
Create GitHub Actions CI/CD integration for running E2E tests on pull requests.

Purpose: Automate E2E test execution to catch regressions before merge. Ensures all tests pass before code reaches main branch.
Output: GitHub Actions workflow that runs smoke, workflow, and responsive tests on every PR.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/quick/004-research-agent-browser-integration/004-RESEARCH.md
@.planning/phases/13-e2e-testing-agent-browser/13-01-SUMMARY.md
@.planning/phases/13-e2e-testing-agent-browser/13-02-SUMMARY.md
@.planning/phases/13-e2e-testing-agent-browser/13-03-SUMMARY.md
@.planning/phases/13-e2e-testing-agent-browser/13-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test orchestrator script</name>
  <files>test/e2e/run-all.js</files>
  <action>
  Create a test orchestrator that runs all E2E tests in sequence:

  ```javascript
  // test/e2e/run-all.js
  import { spawn } from 'child_process';
  import { fileURLToPath } from 'url';
  import { dirname, join } from 'path';

  const __filename = fileURLToPath(import.meta.url);
  const __dirname = dirname(__filename);

  const TESTS = [
    { name: 'Smoke Test', script: 'smoke.js' },
    { name: 'Workflow Test', script: 'workflow.js' },
    { name: 'Responsive Test', script: 'responsive.js' },
    // Note: charts.js excluded from CI - requires visual verification
  ];

  async function runTest(name, script) {
    return new Promise((resolve, reject) => {
      console.log(`\n${'='.repeat(50)}`);
      console.log(`Running: ${name}`);
      console.log('='.repeat(50));

      const testPath = join(__dirname, script);
      const proc = spawn('node', [testPath], {
        stdio: 'inherit',
        shell: true,
      });

      proc.on('close', (code) => {
        if (code === 0) {
          console.log(`\n[PASS] ${name} completed successfully`);
          resolve(true);
        } else {
          console.log(`\n[FAIL] ${name} failed with code ${code}`);
          resolve(false);
        }
      });

      proc.on('error', (err) => {
        console.log(`\n[ERROR] ${name} error: ${err.message}`);
        resolve(false);
      });
    });
  }

  async function runAllTests() {
    console.log('eVelo E2E Test Suite');
    console.log('====================\n');

    const results = [];
    let allPassed = true;

    for (const test of TESTS) {
      const passed = await runTest(test.name, test.script);
      results.push({ name: test.name, passed });
      if (!passed) {
        allPassed = false;
        // Continue running other tests even if one fails
      }
    }

    // Print summary
    console.log('\n');
    console.log('='.repeat(50));
    console.log('TEST SUMMARY');
    console.log('='.repeat(50));

    for (const result of results) {
      const status = result.passed ? '[PASS]' : '[FAIL]';
      console.log(`${status} ${result.name}`);
    }

    const passCount = results.filter(r => r.passed).length;
    console.log(`\nTotal: ${passCount}/${results.length} passed`);
    console.log('='.repeat(50));

    return allPassed;
  }

  runAllTests()
    .then(success => process.exit(success ? 0 : 1))
    .catch(err => {
      console.error('Test suite error:', err);
      process.exit(1);
    });
  ```

  Key design decisions:
  - Run tests sequentially (not parallel) to avoid server conflicts
  - Continue running all tests even if one fails (for full report)
  - Print summary at end with pass/fail counts
  - Exit with appropriate code for CI
  - Exclude charts.js from CI (requires visual verification)
  </action>
  <verify>
  - File exists at test/e2e/run-all.js
  - No syntax errors: node --check test/e2e/run-all.js
  </verify>
  <done>Test orchestrator script created that runs all E2E tests</done>
</task>

<task type="auto">
  <name>Task 2: Create GitHub Actions workflow</name>
  <files>.github/workflows/e2e.yml</files>
  <action>
  Create GitHub Actions workflow for E2E tests:

  ```yaml
  # .github/workflows/e2e.yml
  name: E2E Tests

  on:
    pull_request:
      branches: [main, master]
    push:
      branches: [main, master]
    workflow_dispatch:  # Allow manual trigger

  jobs:
    e2e:
      name: Run E2E Tests
      runs-on: ubuntu-latest
      timeout-minutes: 15

      steps:
        - name: Checkout
          uses: actions/checkout@v4

        - name: Setup Node.js
          uses: actions/setup-node@v4
          with:
            node-version: '20'
            cache: 'npm'

        - name: Install dependencies
          run: npm ci

        - name: Install agent-browser
          run: |
            npm install -g agent-browser
            agent-browser install

        - name: Build application
          run: npm run build

        - name: Run E2E tests
          run: npm run test:e2e
          env:
            CI: true

        - name: Upload screenshots on failure
          if: failure()
          uses: actions/upload-artifact@v4
          with:
            name: e2e-screenshots
            path: test/e2e/screenshots/current/
            retention-days: 7
  ```

  Key considerations:
  - Use ubuntu-latest (agent-browser has Chromium binaries)
  - Cache npm dependencies for faster runs
  - Install agent-browser globally in CI
  - Upload screenshots as artifacts on failure for debugging
  - 15-minute timeout (simulations can take time)
  </action>
  <verify>
  - File exists at .github/workflows/e2e.yml
  - YAML syntax is valid
  </verify>
  <done>GitHub Actions workflow created for E2E tests</done>
</task>

<task type="auto">
  <name>Task 3: Add CI badge to README (if exists)</name>
  <files>README.md</files>
  <action>
  If README.md exists, add CI badge:

  ```markdown
  # eVelo

  [![E2E Tests](https://github.com/{owner}/{repo}/actions/workflows/e2e.yml/badge.svg)](https://github.com/{owner}/{repo}/actions/workflows/e2e.yml)

  ...existing content...
  ```

  If README.md does not exist:
  - Skip this task (don't create README just for badge)
  - Log "README.md not found - skipping CI badge"

  The badge provides:
  - Visual indicator of E2E test status
  - Link to test run details
  </action>
  <verify>
  - If README.md exists: Badge markdown added at top
  - If README.md not exists: Task logged as skipped
  </verify>
  <done>CI badge added to README (or skipped if no README)</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. test/e2e/run-all.js exists and runs all tests
2. .github/workflows/e2e.yml is valid YAML
3. Workflow triggers on PR and push to main/master
4. Workflow installs agent-browser and runs tests
5. Screenshots uploaded as artifacts on failure
</verification>

<success_criteria>
1. run-all.js executes smoke, workflow, responsive tests in sequence
2. run-all.js prints summary with pass/fail counts
3. GitHub Actions workflow runs on pull_request and push
4. Workflow installs Node.js 20 and agent-browser
5. Workflow uploads screenshot artifacts on failure
6. Exit code 0 when all tests pass, non-zero when any fails
</success_criteria>

<output>
After completion, create `.planning/phases/13-e2e-testing-agent-browser/13-06-SUMMARY.md`
</output>
